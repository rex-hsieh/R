---
title: "Basic Exercises in R: Data Structures"
output:
  html_notebook:
    theme: united
    toc: yes
---

We are going to put what we learned in "r_introduction" into practice! Every propmt below corresponds to a particular section of the introduction, and will be clearly labelled. In some cases, either partial answers are provided *or* alternative answers are provided. A simple example is provided below.


# Example: Random Draws from a Population

> Randomly generate 1,000 pets, from the choices "dog", "cat", "goldfish", "monster", each with equal probability of each being chosen. Display the first few values of the resultant variable, and count the number of each type of pet.

This is a classic exercise in statistics/econometrics/any sort of scientific investigation: can I draw randomly from a population with **known** number and types of species?

The answer is: **sort of**, but **yes**. The truth is computers don't really make things randomly, but we will accept it as such because we cannot define randomness.

How do I make sure this happen?

```{r}
(pets <- c("dog", "cat", "goldfish", "monster"))  # But this only gives us the pets! We need to use the factor() data structure

help("factor")  # see what this function does!
help("sample")  # see what this function does!

pets <- factor(sample(
  c("dog", "cat", "goldfish", "monster"),
  1000,
  replace = TRUE
  )
)  # without specifying the probability vector, it is assumed to be uniform.

head(pets)
summary(pets)
```

Does the distribution (ie. the numbers of pets) closely match our initial setup? Is the distribution of pets "uniform" enough?

A slightly interesting variation: suppose we know the population is 30% dogs, 20% cat, 40% goldfish, 10% monster. We can alter the simulation slightly and get:

```{r}
pets <- factor(sample(
  c("dog", "cat", "goldfish", "monster"),
  1000,
  replace = TRUE,
  prob = c(0.3,0.2,0.4,0.1)
  )
)  # without specifying the probability vector, it is assumed to be uniform.

head(pets)
summary(pets)  # total counts after simulation
pets_proportions <- (summary(pets) / 10)  # In percentage form
pets_proportions
```

One can do a lot more things with this setup: professionally/academically, we can use this do something we call *bootstrapping*. The details of this will be left to the statistics classes you will take in the future.




# Manipulating Workspace Variables

> Create some variables named after vegetables. List the names of all the variables in the user workspace that contain the letter "a".

A possible solution is the following:

```{r}
eggplant <- 1
lettuce  <- 2
tomato  <- 3
spinach  <- 4

# HINT: use ls() -- see ls() and its arugments!
```


# Some Arithmetic

> The $n$-th triangular number is given by $\frac{n(n+1)}{2}$. Create a sequence of the first 20 triangular numbers. R has a built-in constant, letters, that contains the lowercase letters of the Roman alphabet. Name the elements of the vector that you just created with the first 20 letters of the alphabet. Select the triangular numbers where the name is a vowel.

A possible solution is:

```{r}
#There are several possibilities for creating sequences, including the colon operator.
n <- 1:20
triangular <- (n * (n+1))/2
names(triangular) <- letters[n]
triangular
```

Can you rewrite the above program using the following functions:

* seq_along()
* seq_len()

```{r}
# Your attempt

```


# Diagonal Matrices

Term 1
: A **diagonal matrix** is any matrix with nonzero entries on its diagonal, but zero everywhere else. For example,
$$ \begin{bmatrix} 1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & -2 \end{bmatrix}  $$
is a $3 \times 3$ diagonal matrix.

> The diag function has several uses, one of which is to take a vector as its input and create a square matrix with that vector on the diagonal. Create a 21-by-21 matrix with the sequence -10 to 0 to 11 (i.e., -10, ... , 1, 0, 1, ,,,m 11).

I will provide a different example: I will create a $10 \times 10$ matrix with sequences -3 to 13.

```{r}
s <- -3:13
diag(s, ncol = 10, nrow = 10)
```

Try it yourself!


```{r}
# Your attempt
```




# Working With Iris

> R ships with several built-in datasets, including the famous3 iris (flowers, not eyes) data collected by Anderson and analyzed by Fisher in the 1930s. Type iris to see the dataset. Create a new data frame that consists of the numeric columns of the iris dataset, and calculate the means of its columns.

```{r}
data <- iris
data
```


# Working with Beavers

> The beaver1 and beaver2 datasets contain body temperatures of two beavers. Add a column named id to the beaver1 dataset, where the value is always 1. Similarly, add an id column to beaver2, with value 2. Vertically concatenate the two data frames and find the subset where either beaver is active.

```{r}
# Your attempt
# Use rbind() and subset() --- these will make your life easier!
```


# Working with Even and Odd Integers

This is difficult, but we will get there together:

> Write a function that accepts a vector of integers (for simplicity, you don't have to worry about input checking) and returns a logical vector that is TRUE whenever the input is even, FALSE whenever the input is odd, and NA whenever the input is nonfinite (nonfinite means anything that will make is.finite return FALSE: Inf, -Inf, NA, and NaN). Check that the function works with positive, negative, zero, and nonfinite inputs.

How does one do this? Well, we need to know that whenever a number is even, it is **divisible by 2**. So, of the vector below:

```{r}
numbers <- c(1,2,3,4,5,6,7,8,9,10)
(numbers_mod_2 <- numbers %% 2)
```

The "%%" sign means "modulo", a fancy way of saying division by some number following it. So "%% 2" means division by two, and the result it spits out is the remainder! So,

```{r}
(4 %% 3)  # = 1, because 4 = 3 x 1 + 1 !
```

So we are going to write function that takes $x$ and spits out the remainders of the elements upon division by 2!

I am going to do a variation on this exercise: I wonder if it is possible to identify odd numbers using the same method. The answer is **yes**, because odd numbers are those with remainder 1 upon division by 2 (this approach works well with small numbers, but NOT for huge numbers --- this is something we won't care much for, because the mathematical background needed for writing better algorithms is too daunting). So, I can write

```{r}
is_odd <- function(x){
  x %% 2 == 1  #  Check if the remainder of x divided by 2 = 1. Remember the == operator returns a logical / boolean value!
}
is_odd(101)
is_odd(c(-5:5, Inf, -Inf, NA, NaN))
example <- as.data.frame( cbind( values = c(-5:5, Inf, -Inf, NA, NaN), parity = is_odd(c(-5:5, Inf, -Inf, NA, NaN)) ) )
example$parity <- ifelse(example$parity == 1, TRUE, FALSE)  # replace 1 with TRUE and 0 with FALSE.
```

Give the question a try! 

```{r}
is_even <- function(x){
  # YOUR ATTEMPT
}
is_even(20)  # should return TRUE
is_even(c(-5:5), Inf, -Inf, NA, NaN))
```


# Simple Maths

> Display the value of pi to 16 significant digits.

```{r}
pi
# HINT: use format -- I've done most of the work here.
(format(pi, digits = ))
```


# A Hypothetical Game

> For your role-playing game, each of your adventurer's character attributes is calculated as the sum of the scores from three six-sided dice rolls. To save arm-ache, you decide to use R to generate the scores. Here's a helper function to generate them:

```{r}
#n specifies the number of scores to generate.
#It should be a natural number.
three_d6 <- function(n){
  random_numbers <- matrix(
    sample(6, 3 * n, replace = TRUE),
    nrow = 3
    )
  colSums(random_numbers)
}
```


> Big scores give characters bonuses, and small scores give characters penalties, according to the following table:

| Score    | Bonus |
|----------|-------|
| 3        | -3    |
| 4,5      | -2   |
| 6 to 8   | -1     |
| 9 to 12  | 0 |
| 13 to 15 | 1 |
| 16, 17   | 2  |
| 18       | 3   |

> Use the three_d6 function to generate 1000 character attribute scores. Create a table of the number of scores with different levels of bonus.

For a *small* sample, I will generate the bonus table for yoU for a small sample. Please replicate this for 1000 by yourself:

```{r}
y <- three_d6(10)
# Use the cut() function!

bonus <- cut(y,
             c(2,3,5,7,12,15,17,18),  # cut by UPPER BOUNDS
             labels = -3:3
             )
table(bonus)
```

Once you generate a larger output, think about the probability of getting bonuses given the scores. Is it more likely to get a bonus of 0 than bonus of 1, for example? If not, what is happening in this simulation? Is this a close approximation of reality / probabilistic thought experiment? What if my sample is 1 million?
