---
title: "R: Intermediate Level Material"
author: Meng Hsuan Hsieh
output:
  html_notebook:
    theme: united
    toc: yes
---

Having learned the basic data structures of R, we now turn our focus to some intermediate level coding topics. We assume a fair bit of coding skills and logic in this tutorial. We will begin with specifying environments, functions, loops, and eventually make our way into data analysis --- which si the bulk of the materials in the next tutorial.


# Environments

All the variables that we create need to be stored somewhere, and that somewhere is an environment. Environments themselves are just another type of variable --- we can assign them, manipulate them, and pass them into functions as arguments, just like we would any other variable. They are closely related to lists in that they are used for storing different types of variables together. In fact, most of the syntax for lists also works for environments, and we can coerce a list to be an environment (and vice versa).

If you ever worked in some sort of computer language, storing objects is of a concern. However, Usually, you won't need to explicitly deal with environments. For example, when you assign a variable at the command prompt, it will automatically go into an environment called the global environment (also known as the user workspace). When you call a function, an environment is automatically created to store the function-related variables. Understanding the basics of environments can be useful, however, in understanding the scope of variables, and for examining the call stack when debugging your code.

One can easily add a new environment by the following command:

```{r}
an_environment <- new.env()
```

which, in the environment tab in RStudio, is labelled as "Environment", as expected. Assigning a variable to an environment is equally easy: it takes an extra second to write,

```{r}
an_environment[["pythag"]] <- c(12, 15, 20, 21) #See http://oeis.org/A156683
an_environment$root <- polyroot(c(6, -5, 1))
```

Similarly, we can use the *assign()* function to put objects into an environment of our choice:

```{r}
assign(
"moonday",
weekdays(as.Date("1966/05/01")),
an_environment
)
```

We can also easily read variables stored in these environment:

```{r}
ls(envir = an_environment)
ls.str(envir = an_environment)
```

And we can tell if an object lives in an environment by using the following command:

```{r}
exists("pythag", an_environment)
```

It is possible to turn environments into a list, and vice versa; the underlying reason why this is possible is, again, due to the flexibility of these environments.

```{r}
#Convert to list
(a_list <- as.list(an_environment))
as.environment(a_list)
list2env(a_list)
```

Important note: all environments are nested, meaning that they must have a parent environment (the exception is a special environment called the **empty environment** that sits at the top of the chain). By default, the exists and get functions will also look for variables in the parent environments. Pass inherits = FALSE to them to change this behavior so that they will only look in the environment that you’ve specified:

```{r}
nested_environment <- new.env(parent = an_environment)
exists("pythag", nested_environment)
exists("pythag", nested_environment, inherits = FALSE)
```

Shortcut functions are available to access both the global environment (where variables that you assign from the command prompt are stored) and the base environment (this contains functions and other variables from R’s base package, which provides basic functionality):

```{r}
non_stormers <<- c(3, 7, 8, 13, 17, 18, 21) #See http://oeis.org/A002312
get("non_stormers", envir = globalenv())
head(ls(envir = baseenv()), 20)
```


There are two other situations where we might encounter environments.

1. Whenever a function is called, all the variables defined by the function are stored in an environment belonging to that function (a function plus its environment is sometimes called a closure).
2. Whenever we load a package, the functions in that package are stored in an environment on the search path.


# Functions

This is extremely useful, and, beyond undergraduate level in econometrics or statistical modelling classes, functions are used for any serious modelling/estimation procedures. In order to understand functions better (this is actually not that different from Python functions), let’s take a look at what they consist of. Typing the name of a function shows you the code that runs when you call it. This is the *rt* function, which generates random numbers from a Student's t-distribution:

```{r}
rt
```

Let's try to combine some stuff in pratice:

```{r}
stats_env <- new.env()
t_dist <- rt(200,1)
assign(
"t-dist-ex",
t_dist,
stats_env
)
```

As you can see from the previous output, the function parameters and syntax are quite easy to write down. Also, different from functions in Python, for example, there is no explicit “return” keyword to state which value should be returned from the function. In R, the last value that is calculated in the function is automatically returned. In the case of *rt*, if the *ncp* (used for calculating non-central t-distribution) argument is omitted, some *C* code is called to generate the random numbers, and those are returned. Otherwise, the function calls the *rnorm*, *rchisq*, and *sqrt* functions to generate the numbers, and those are returned.

To create our own functions, we just assign them as we would any other variable. As an example, let’s create a function to calculate the length of the hypotenuse of a right-angled triangle (for simplicity, we’ll use the obvious algorithm; for real-world code, this doesn’t work well with very big and very small numbers, so you shouldn’t calculate hypotenuses this way):

```{r}
options(scipen=999)
hypotenuse <- function(x, y){
  # format(sqrt(x ^ 2 + y ^ 2), scientific = FALSE)
  sqrt(x ^ 2 + y ^ 2)
}
hypotenuse(10,20)
```

Just for intellectual curiosity, why does this code not work so well? The answer is implicit in *machine accuracy*: the code above works in theory, but in practice it may fail. If $x$ is so large that $x^2$ overflows, the code will produce an infinite result. We’d like to be able to say to the computer "Now $x^2$ and $y^2$ might be too big, but just wait a minute. I’m going to take a square root, and so the numbers will get smaller. I just need to borrow some extra range for a minute". I know this is a long heuristic, but this is exactly what good mathematics is about: one can achieve machine limitations like that in environments by extending precision, but that would be inefficient and unnecessary. And of course it would fail completely if you’re already using the largest numeric type available. Hence, we use the following algorithm to avoid overflow: it is not the best code out there, but it works far more reliably than the last:

```{r}
hypo_large <- function(x,y){
  max_xy = max(abs(x),abs(y))
  min_xy = min(abs(x),abs(y))
  r = min_xy / max_xy
  # format(max_xy * sqrt(1+r^2),scientific = FALSE)
  max_xy * sqrt(1+r^2)
}
hypo_large(10,20)
```

but check out the following:

```{r}
start_time <- Sys.time()
system.time({hypotenuse(12839081902859018902809189658908690849062830946802934860928309468902384068,1923091029309120390192309851894534534534537898643120591)})
hypotenuse(12839081902859018902809189658908690849062830946802934860928309468902384068,1923091029309120390192309851894534534534537898643120591)
end_time <- Sys.time()

end_time - start_time
```

```{r}
start_time <- Sys.time()
system.time({hypo_large(12839081902859018902809189658908690849062830946802934860928309468902384068,1923091029309120390192309851894534534534537898643120591)})
hypo_large(12839081902859018902809189658908690849062830946802934860928309468902384068,1923091029309120390192309851894534534534537898643120591)
end_time <- Sys.time()

end_time - start_time
```

Granted, these are "small" numbers by machine standards, so printing them in the interpreter is not so much of a problem. But look at the runtime differences: the "approximation" algorithm is slightly faster than the regular, theory-based algorithm.

A piece of theory that is good to know is that we can always standardise a normal random variable so that it has mean 0 and variance 1. We will see it in practice first:

```{r}
normalize <- function(x, m = mean(x), s = sd(x)){
  (x - m) / s
} 
normalized <- normalize(c(1, 3, 6, 10, 15))
mean(normalized) #almost 0!
sd(normalized)
```

And notice the following: if a part of the argument is missing, then the function returns a series of NAs:

```{r}
normalize(c(1, 3, 6, 10, NA))
```

To make this problem go away, we need to explicitly tell R that it is okay to have no arguments inside these functions; to do so, we need to specify one more arugment:

```{r}
normalize <- function(x, m = mean(x, na.rm = na.rm),
s = sd(x, na.rm = na.rm), na.rm = FALSE){
  (x - m) / s
}
normalize(c(1, 3, 6, 10, NA))
normalize(c(1, 3, 6, 10, NA), na.rm = TRUE)
```

This is much better, but we still have the problem that the syntax is quite clunky. To resolve this, R is a clever syntax, ..., that will allow us to do less writing in the process:

```{r}
normalize <- function(x, m = mean(x, ...), s = sd(x, ...), ...){
  (x - m) / s
}
normalize(c(1, 3, 6, 10, NA))
normalize(c(1, 3, 6, 10, NA), na.rm = TRUE)
```

Now in the call normalize(c(1, 3, 6, 10, NA), na.rm = TRUE), the argument na.rm does not match any of the formal arguments of normalize, since it isn't x or m or s. That means that it gets stored in the ... argument of normalize. When we evaluate m, the expression mean(x, ...) is now mean(x, na.rm = TRUE).

If this isn't clear right now, don't worry. How this works is an advanced topic, and most of the time we don't need to worry about it. For now, you just need to know that ... can be used to pass arguments to subfunctions.


One can also easily pass onto functions from one to another; the trick is to use *do.call()*:

```{r}
do.call(hypotenuse, list(x = 3, y = 4)) # This is the same as hypotenuse(3,4)
```

Perhaps the most common use case for do.call is with rbind. You can use these two functions together to concatenate several data frames or matrices together at once:

```{r}
dfr1 <- data.frame(x = 1:5, y = rt(5, 1))
dfr2 <- data.frame(x = 6:10, y = rf(5, 1, 1))
dfr3 <- data.frame(x = 11:15, y = rbeta(5, 1, 1))
do.call(rbind, list(dfr1, dfr2, dfr3)) #same as rbind(dfr1, dfr2, dfr3)
```

We can always pass functions into the argument explicitly by typing out all the components, but we can also do it implicitly by means of a trick similar to *lambda* expression in Python:

```{r}
x_plus_y <- function(x, y) x + y
do.call(x_plus_y, list(1:5, 5:1))
#is the same as
do.call(function(x, y) x + y, list(1:5, 5:1))
```

There are functions that return functions:

```{r}
(emp_cum_dist_fn <- ecdf(rnorm(50)))
is.function(emp_cum_dist_fn)
plot(emp_cum_dist_fn)
```

Now, we are ready to speak of a big idea.

## Variable Scope

A variable's scope is the set of places from which you can see the variable. For example, when you define a variable inside a function, the rest of the statements in that function will have access to that variable. In R (but not S), subfunctions will also have access to that variable. In this next example, the function f takes a variable x and passes it to the function g. f also defines a variable y, which is within the scope of g, since g is a subfunction of f.

```{r}
f <- function(x)
{
  y <- 1
  g <- function(x)
  {
    (x + y) / 2 #y is used, but is not a formal argument of g
  }
  g(x)
}
f(sqrt(5)) #It works! y is magically found in the environment of f
```

The remark I will make here is that **global variables** should be defined and used as sparingly as possible. 

```{r}
y <- 19

h2 <- function(x)
{
  if(runif(1) > 0.5) y <- 12
  x * y
}

replicate(10, h2(9))
```

See the problem here? If the uniform draw is greater than 0.5, then y is defined as 12. Otherwise, y is define as 16. It is often better to pass arguments into the function as necessary, rather than before defining it straight up.



# Strings and Factors

Text data is stored in character vectors (or, less commonly, character arrays). It's important to remember that each element of a character vector is a whole string, rather than just an individual character. In R, "string" is an informal term that is used because "element of a character vector" is quite a mouthful. The fact that the basic unit of text is a character vector means that most string manipulation functions operate on vectors of strings, in the same way that mathematical operations are vectorized.

The c() function is used to create the desired string:

```{r}
c(
  "You should use double quotes most of the time",
  'Single quotes are better for including " inside the string'
)
```

The paste function combines strings together. Each vector passed to it has its elements recycled to reach the length of the longest input, and then the strings are concatenated, with a space separating them. We can change the separator by passing an argument called *sep*, or use the related function paste0 to have no separator. After all the strings are combined, the result can be collapsed into one string containing everything using the collapse argument:

```{r}
paste(c("red", "yellow"), "lorry")
paste(c("red", "yellow"), "lorry", sep = "-")
paste(c("red", "yellow"), "lorry", collapse = ", ")
paste0(c("red", "yellow"), "lorry")
```

```{r}
x <- (1:15) ^ 2
toString(x)
toString(x, width = 40)
```

```{r}
x <- c(
"I", "saw", "a", "saw", "that", "could", "out",
"saw", "any", "other", "saw", "I", "ever", "saw"
)
y <- noquote(x)
x
y
```

## Formatting Numbers

Explicitly, R does a bunch of formatting using C-style commands. There are specifications that allow you to specify fixed or scientific formatting, the number of decimal places, and the width of the output. Whatever the options, the input should be one of the numeric types (including arrays), and the output is a character vector or array:

```{r}
pow <- -2:6
(powers_of_e <- exp(pow))
formatC(powers_of_e)
formatC(powers_of_e, digits = 3) #3 sig figs
formatC(powers_of_e, digits = 3, width = 10) #preceding spaces
formatC(powers_of_e, digits = 3, format = "e") #scientific formatting
formatC(powers_of_e, digits = 3, flag = "+") #precede +ve values with +
```

R also provides slightly more general C-style formatting with the function sprintf. This works in the same way as sprintf in every other language: the first argument contains placeholders for string or number variables, and further arguments are substituted into those placeholders. Just remember that most numbers in R are floating-point values rather than integers.

The first argument to sprintf specifies a formatting string, with placeholders for other values. For example, %s denotes another string, %f and %e denote a floating-point number in fixed or scientific format, respectively, and %d represents an integer. Additionalarguments specify the values to replace the placeholders. As with the paste function, shorter inputs are recycled to match the longest input:

```{r}
sprintf("%s %d = %f", "Euler's constant to the power", pow, powers_of_e)
sprintf("To three decimal places, e ^ %d = %.3f", pow, powers_of_e)
sprintf("In scientific notation, e ^ %d = %e", pow, powers_of_e)
```

One can also use either *format()* or *prettyNum()* function from the formatC package:

```{r}
format(powers_of_e)
format(powers_of_e,digits = 4) # this corrects up to 4 significant digits
format(powers_of_e,digits = 4, trim=TRUE) # this removes all leading zeros
format(powers_of_e,digits = 4, scientific = TRUE)
```

We can also explicitly change upper and lower cases by using the toupper() and tolower() functions. Splitting strings by spaces or other delimiters is also possible, but require little more care in doing so. This is not so interesting, so please consult the book for more examples.



## Factors

**Factors** are a special variable type in R that stores categorical data. There are lots of evidence that this is useful, but also a lot of scenarios where this is not the most well-behaved or predictable data structure.

To create a factor, the command is extremely simple:

```{r}
(heights <- data.frame(
  height_cm = c(153, 181, 150, 172, 165, 149, 174, 169, 198, 163),
    gender = c("female", "male", "female", "male", "male",
              "female", "female", "male", "male", "female")
))
class(heights$gender)
```

It is extremely important to speak of the *levels* that a particular factor contains. We need to clarify a few things:

```{r}
class(heights$gender)
heights$gender
levels(heights$gender)

# Creating factors is as easy as using the factor function:

gender_char <- c(
      "female", "male", "female", "male", "male",
      "female", "female", "male", "male", "female"
      )
(gender_fac <- factor(gender_char))
```

And looking at these new factors give us
```{r}
gender_fac
```

We can change the order of the levels when the factor is created by specifying a levels argument:

```{r}
factor(gender_char, levels = c("male", "female"))
```

and we can change the order of the factor levels by using the factor function again --- only this time passing into the existing factor (rather than the character vector we created earlier):

```{r}
factor(gender_fac, levels = c("male", "female"))
```

The relevel function is an alternative way of changing the order of factor levels. In this case, it just lets you specify which level comes first. As you might imagine, the use case for this function is rather niche --- it can come in handy for regression models where you want to compare different categories to a reference category. We will talk at length about this later. Most of the time you will be better off calling factor if you want to set the levels:

```{r}
relevel(gender_fac, "male")
```

## Dropping Factors Levels

There are instances where some levels are undesirable to keep in the data. For example, it is entirely possible that some factors contain NAs.

```{r}
getting_to_work <- data.frame(
      mode = c(
        "bike", "car", "bus", "car", "walk",
        "bike", "car", "bike", "car", "car"
        ),
time_mins = c(25, 13, NA, 22, 65, 28, 15, 24, NA, 14)
)

(getting_to_work <- subset(getting_to_work, !is.na(time_mins)))

unique(getting_to_work$mode)


```

We can always drop the unused levels of the factor: in this case, we can use the *droplevels()* function. This accepts either a factor or a data frame. In the latter case, it drops the unused levels in all the factors of the input. Since there is only one factor in our example data frame, the two lines of code in the next example are equivalent:

```{r}
getting_to_work$mode <- droplevels(getting_to_work$mode)
getting_to_work <- droplevels(getting_to_work)
levels(getting_to_work$mode)
```


We can always order factors if we want; for example sake, let us generate 10,000 responses (pseudo-random, of course) and see what we have.

```{r}
happy_choices <- c("depressed", "grumpy", "so-so", "cheery", "ecstatic")
happy_values <- sample(
  happy_choices, 10000,
  replace = TRUE
)
happy_fac <- factor(happy_values, happy_choices)
head(happy_fac)
happy_fac
```

And we can order this by using the *ordered()* function:

```{r}
happy_ord <- ordered(happy_values, happy_choices)
head(happy_ord)
```
which, by default, assumes the "<" relation!

An ordered factor is a factor, but a normal factor isn’t ordered: to see what I am saying, see the following output

```{r}
is.factor(happy_ord)
is.ordered(happy_ord)
is.ordered(happy_fac)
```

There will be times when it is desirable to cnovert factors data to numerical data, and that is the whole point of data cleaning. For example, if there is a mistyped data, R is smart enough to recognise it as factor type, but not so much anything else. As such, we have the embarrassing case of

```{r}
dirty <- data.frame(
  x = c("1.23","4..55","30.12")
)
as.numeric(dirty$x)
```
and the *as.numeric()* command is obviously wrong. A recommended course of action for such conversion is to first convert factors' levels to numeric, then put everything as numeric or integer. This means

```{r}
as.numeric(levels(dirty$x))[as.integer(dirty$x)]
```
an alternative is clunkier, but still works:
```{r}
as.numeric(as.character(dirty$x))
```
first by converting dirty$x to characters (which does one conversion) and then to numeric (another conversion).

The first method (the less clunky one) is more preferable but less intuitive; hence, if we are to code it, it is often times better to wrap it in function:

```{r}
factor_to_numeric <- function(f){
  as.numeric(levels(f))[as.integer(f)]
}
dirty$x <- factor_to_numeric(dirty$x)
dirty$x[is.na(dirty$x)] <- 0
dirty
```
and something like above is implemented fairly often in the context of data cleaning --- which is something we will not be doing a lot in our work.

A dataset is **balanced** if every cell contains a valid data type, and every category has the same number of data. The first is checked --- since there are a lot of data types built into R, all of which mapped to by some element. The second is harder; in an abstract, non-real-world-application-type setting, the *gl()* function can be used to generate a factor. In its simplest form, the function takes an integer for the number of levels in the resultant factor, and another integer for how many times each level should be repeated. More commonly, you will want to set the names of the levels, which is achieved by passing a character vector to the labels argument. More complex level orderings, such as alternating values, can be created by also passing a length argument:

```{r}
gl(3, 2)
gl(3, 10)
gl(3, 2, labels = c("placebo", "drug A", "drug B"))
gl(3, 1, 10, labels = c("placebo", "drug A", "drug B")) #alternating
```

The term "interaction" should sound familiar if you have dealt with some statistical theory, but in the context of creating factors, this is how we combine multiple levels.

```{r}
treatment <- gl(3, 2, labels = c("placebo", "drug A", "drug B"))
gender <- gl(2, 1, 6, labels = c("female", "male"))
interaction(treatment, gender)
```


# Flow Control and Loops
This is an immensely important topics. Sometimes, the functions we are executing will fail because

1. inputs are incorrect / misspecfied
2. output presents a programmatic error
3. functions are wrongly specified

The latter two cases can be corrected by being careful; the first is tricky *if* we did not consider the all possible inputs to begin with. In other words, if we do not correctly specify the function's arguments (inputs), we might run into problems executing it --- or, even worse, return undesirable results!

The *if,,,else,,,* syntax in R is powerful for multiple reasons --- not the least of which because it allows us to circumvent the issue of misspecification/wrongly specified inputs.

Even by way of example, let us avoid the trivial cases where entering TRUE and FALSE each returns different things; we want to have some mix of syntax/expression, each of which returns different results. Here is a nontrivial example:

```{r}
x <- rnorm(1,0,1)
x
if(abs(x) > 0.5) print("OMG") else print("ONO")
```

and the basic syntax is simple:

```{r,eval=FALSE}
if(FALSE)
{
  message("This won't execute...")
} else
{
  message("but this will.")
}
```

And R allows some nifty enough nesting of if-else commands (notice that this is NOT ifelse(); that is something else):

```{r}
(r <- round(rnorm(2), 1))
(x <- r[1] / r[2])

if(is.nan(x))
  {
  message("x is missing")
  } else if(is.infinite(x))
    {
    message("x is infinite")
    } else if(x > 0)
      {
      message("x is positive")
      } else if(x < 0)
        {
        message("x is negative")
        } else
          {
            message("x is zero")
          }
```

In addition, conditional statement can be embedded in if statements!

```{r}
x <- sqrt(-1 + 0i)
(reality <- if(Re(x) == 0) "real" else "imaginary")
```

## Vectorised Version of if-else: ifelse()

Since much of R is written and done in vectors, the vectorised version of if...else... is done by ifelse() (for those who are intellectually curious, try a vector as simple as x <- c(1,2,3) and use if...else... on it; you will see an error message with length > 1 as its traceback). ifelse() takes three arguments --- visit help page or type help(ifelse) into interpreter for more information. Bottomline: it takes a test statement, a returned expression for when the test returns TRUE, an another for when the test returns FALSE.

By way of example, see the following randomly generated distribution values:

```{r}
ifelse(rbinom(10, 1, 0.5), "Head", "Tail")
x <- rnorm(10,0,1) > 0.5
ifelse(x > 0.5, "Yes", "No")  # Syntax-wise, this can be reduced to simpler things, but for all practical purposes and code readability, this is desirable.
```

Slightly less cumbersome/clunky code can be achieved if we use the *switch()* function instead: notice if the switch input does not match any of the code after, it will automatically return NULL:

```{r}
nthroot <- function(x,n){
  x^{1/n}
}

numbers_game <- function(x){
  switch(
    as.character(x),
    one = nthroot(rnorm(1,50,15),4),
    two = sqrt(rnorm(1,50,15)),
    three =
    {
      a <- cos(pi / (rnorm(1,50,15)))
      (4 * a)^2
    }
  )
}
x <- "three"
y <- "two"
z <- "one"
(c(numbers_game(x), numbers_game(y), numbers_game(z)))
```


## repeat Loops
This is the easiest family of loops, since it requires only repeating things over and over again. The following example should be extremely self-explanatory:

```{r}
repeat
{
  message("Happy Groundhog Day!")
  action <- sample(
    c("Learn French",
      "Make an ice statue",
      "Rob a bank",
      "Win heart of Andie McDowell"
      ),
      1
    )
    if(action == "Rob a bank")
    {
      message("Quietly skipping to the next iteration")
      next
    }
    message("action = ", action)
    if(action == "Win heart of Andie McDowell") break
}
```

## while Loops

This is also fairly self-explanatory --- though I will say this is kind of like a backwards *repeat* loop:

```{r}
action <- sample(
  c(
    "Learn French",
    "Make an ice statue",
    "Rob a bank",
    "Win heart of Andie McDowell"
    ),
  1
  )
while(action != "Win heart of Andie McDowell") # while action is NOT "Win heart of Andie McDowell"
  {
  message("Happy Groundhog Day!")
  action <- sample(
    c(
      "Learn French",
      "Make an ice statue",
      "Rob a bank",
      "Win heart of Andie McDowell"
    ),
  1
  )
  message("action = ", action)
  }
```


## for Loops

This is popular when we know exactly how many times we need to calculate an expression. This is a staple of numerical computations, one that is extremely useful for our purposes later on.

```{r}
# simple example
for(i in 1:5) message("i = ", i)
```

```{r}
# harder example
for(i in 1:5)
  {
    j <- i ^ 2
    message("j = ", j)
  }
```

R’s for loops are particularly flexible in that they are not limited to integers, or even numbers in the input. We can pass character vectors, logical vectors, or lists:

```{r}
for(month in month.name)
  {
    message("The month of ", month)
  }
```

```{r}
yn <- sample(c(TRUE,FALSE,NA))

for(yn in c(TRUE, FALSE, NA))
  {
    message("This statement is ", yn)
  }
```

```{r}
l <- list(
  pi,
  LETTERS[1:5],
  charToRaw("not as complicated as it looks"),
  list(
    TRUE
  )
)

for(i in l)
{
  print(i)
}
```

Last remark: since for loops operate on each element of a vector, they provide a sort of "pretend vectorization". In fact, the vectorized operations in R will generally use some kind of for loop in internal C code. But be warned: R’s for loops will almost always run much slower than their vectorized equivalents, often by an order of magnitude or two. This means that you should try to use the vectorization capabilities wherever possible.

A far more problematic claim is the widespread agreement that if one writes R code that looks like Fortran, one loses the right to complain that R is too slow.

